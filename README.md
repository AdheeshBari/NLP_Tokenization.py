# NLP_Tokenization.py
This script tokenizes text from a file into sentences and words using NLTK, providing a foundation for NLP processing.

This script demonstrates basic text tokenization in Python using the Natural Language Toolkit (NLTK). It reads a text file specified by the user, then splits the content into sentence tokens and word tokens for further NLP processing.

How It Works
1. Input File Path: The script prompts the user to input the file path of a text file.
2. File Reading: It opens and reads the file's content in UTF-8 encoding.
3. Sentence Tokenization: Using sent_tokenize, it breaks the content into sentences.
4. Word Tokenization: Using word_tokenize, it splits the content into individual words and punctuation.
5. Output: Finally, it prints the lists of sentence tokens and word tokens to the console.
This code serves as a basic foundation for more complex NLP tasks, enabling a quick look at sentence and word structure in a given text file.
